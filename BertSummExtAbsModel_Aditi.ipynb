{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are three ways to run BertSum  \n",
    "- Use the Entirely pretrained Model. You can directly run your test on this Model without training\n",
    "- Use the Bert pretrained model and add fine tuning on top of it for summarization.. You need to train this Model\n",
    "- Use Transformer summarization code : This is similar concept as pt 2 above, but the code is different. I will run it to see if it gives a different Rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os, sys, re, json, time, datetime, shutil\n",
    "import nltk\n",
    "import sentencepiece as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from transformers import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n",
      "0.24.2\n",
      "1.14.0\n",
      "1.3.0.post2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check versions\n",
    "print(np.__version__)\n",
    "print(pd.__version__)\n",
    "print(tf.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CNN/DailyMail dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BertSum team has already preprocessed the data and split it into train,test and validation set in the .pt format.The .pt files are located in PreSumm/bert_data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN_DM abstractive from Pretrained Model\n",
    "\n",
    "The BertSum pretrained model is downloaded and stored in PreSumm/pretrained folder. model_step_148000.pt is the abstractive pretrained model and bertext_cnndm_transformer.pt is the extractive pretained model. You can directly evaluate or test the model - no need to train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adas1/Aditi/personal/school/266/project/PreSumm/src\n"
     ]
    }
   ],
   "source": [
    "%cd PreSumm/src"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model for ~1K dataset along with the Rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-09 08:59:13,583 INFO] Loading checkpoint from ../pretrained/model_step_148000.pt\n",
      "Namespace(accum_count=1, alpha=0.95, batch_size=32, beam_size=5, bert_data_path='../small_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/pretrained_abs_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../results/pretrained_abs_bert_cnndm_sample', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../pretrained/model_step_148000.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2019-11-09 08:59:15,216 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpb45kc_tg\n",
      "100%|██████████████████████████████████████| 313/313 [00:00<00:00, 142977.25B/s]\n",
      "[2019-11-09 08:59:15,616 INFO] copying /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpb45kc_tg to cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 08:59:15,616 INFO] creating metadata file for ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 08:59:15,617 INFO] removing temp file /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpb45kc_tg\n",
      "[2019-11-09 08:59:15,617 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 08:59:15,617 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 08:59:16,024 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpwr7xjh08\n",
      "100%|████████████████████████| 440473133/440473133 [00:32<00:00, 13722679.01B/s]\n",
      "[2019-11-09 08:59:48,595 INFO] copying /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpwr7xjh08 to cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 08:59:49,105 INFO] creating metadata file for ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 08:59:49,105 INFO] removing temp file /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpwr7xjh08\n",
      "[2019-11-09 08:59:49,115 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 08:59:52,690 INFO] Loading test dataset from ../small_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
      "[2019-11-09 08:59:53,147 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpkiiiu_pk\n",
      "100%|████████████████████████████████| 231508/231508 [00:00<00:00, 881998.36B/s]\n",
      "[2019-11-09 08:59:53,805 INFO] copying /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpkiiiu_pk to cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-11-09 08:59:53,806 INFO] creating metadata file for ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-11-09 08:59:53,807 INFO] removing temp file /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpkiiiu_pk\n",
      "[2019-11-09 08:59:53,807 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-11-09 11:02:22,089 INFO] Calculating Rouge\n",
      "1485\n",
      "1485\n",
      "2019-11-09 11:02:22,409 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2019-11-09 11:02:22,409 INFO] Writing summaries.\n",
      "2019-11-09 11:02:22,409 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp3ioupyxy/system and model files to ../temp/tmp3ioupyxy/model.\n",
      "[2019-11-09 11:02:22,409 INFO] Processing summaries. Saving system files to ../temp/tmp3ioupyxy/system and model files to ../temp/tmp3ioupyxy/model.\n",
      "2019-11-09 11:02:22,409 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-11-02-22/candidate/.\n",
      "[2019-11-09 11:02:22,409 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-11-02-22/candidate/.\n",
      "2019-11-09 11:02:22,680 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp3ioupyxy/system.\n",
      "[2019-11-09 11:02:22,680 INFO] Saved processed files to ../temp/tmp3ioupyxy/system.\n",
      "2019-11-09 11:02:22,680 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-11-02-22/reference/.\n",
      "[2019-11-09 11:02:22,680 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-11-02-22/reference/.\n",
      "2019-11-09 11:02:22,966 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp3ioupyxy/model.\n",
      "[2019-11-09 11:02:22,966 INFO] Saved processed files to ../temp/tmp3ioupyxy/model.\n",
      "2019-11-09 11:02:22,976 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp7bkaonjy/rouge_conf.xml\n",
      "[2019-11-09 11:02:22,976 INFO] Written ROUGE configuration to ../temp/tmp7bkaonjy/rouge_conf.xml\n",
      "2019-11-09 11:02:22,976 [MainThread  ] [INFO ]  Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp7bkaonjy/rouge_conf.xml\n",
      "[2019-11-09 11:02:22,976 INFO] Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp7bkaonjy/rouge_conf.xml\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.43080 (95%-conf.int. 0.42318 - 0.43894)\n",
      "1 ROUGE-1 Average_P: 0.40984 (95%-conf.int. 0.40225 - 0.41759)\n",
      "1 ROUGE-1 Average_F: 0.40674 (95%-conf.int. 0.40032 - 0.41391)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.19565 (95%-conf.int. 0.18846 - 0.20287)\n",
      "1 ROUGE-2 Average_P: 0.18755 (95%-conf.int. 0.18036 - 0.19431)\n",
      "1 ROUGE-2 Average_F: 0.18518 (95%-conf.int. 0.17845 - 0.19176)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.39888 (95%-conf.int. 0.39164 - 0.40683)\n",
      "1 ROUGE-L Average_P: 0.38014 (95%-conf.int. 0.37271 - 0.38773)\n",
      "1 ROUGE-L Average_F: 0.37694 (95%-conf.int. 0.37059 - 0.38383)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-09 11:02:37,474 INFO] Rouges at step 148000 \r\n",
      ">> ROUGE-F(1/2/3/l): 40.67/18.52/37.69\r\n",
      "ROUGE-R(1/2/3/l): 43.08/19.56/39.89\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py -task abs -mode test -test_from ../pretrained/model_step_148000.pt -batch_size 32 -test_batch_size 500 -bert_data_path ../small_data/cnndm -log_file ../logs/pretrained_abs_bert_cnndm -report_rouge True  -sep_optim true -use_interval true -visible_gpus -1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../results/pretrained_abs_bert_cnndm_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN_DM extractive from Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adas1/Aditi/personal/school/266/project/PreSumm/src\n",
      "[2019-11-09 11:26:00,754 INFO] Loading checkpoint from ../pretrained/bertext_cnndm_transformer.pt\n",
      "Namespace(accum_count=1, alpha=0.95, batch_size=32, beam_size=5, bert_data_path='../small_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/pretrained_ext_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../models/', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../results/pretrained_ext_bert_cnndm_sample', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../pretrained/bertext_cnndm_transformer.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2019-11-09 11:26:01,920 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 11:26:01,921 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 11:26:02,295 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 11:26:04,123 INFO] Loading test dataset from ../small_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
      "gpu_rank 0\n",
      "[2019-11-09 11:26:04,130 INFO] * number of parameters: 120512513\n",
      "1485\n",
      "1485\n",
      "2019-11-09 11:49:13,501 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2019-11-09 11:49:13,501 INFO] Writing summaries.\n",
      "2019-11-09 11:49:13,501 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmp_nrp7e5z/system and model files to ../temp/tmp_nrp7e5z/model.\n",
      "[2019-11-09 11:49:13,501 INFO] Processing summaries. Saving system files to ../temp/tmp_nrp7e5z/system and model files to ../temp/tmp_nrp7e5z/model.\n",
      "2019-11-09 11:49:13,501 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-11-49-13/candidate/.\n",
      "[2019-11-09 11:49:13,501 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-11-49-13/candidate/.\n",
      "2019-11-09 11:49:13,782 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp_nrp7e5z/system.\n",
      "[2019-11-09 11:49:13,782 INFO] Saved processed files to ../temp/tmp_nrp7e5z/system.\n",
      "2019-11-09 11:49:13,782 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-11-49-13/reference/.\n",
      "[2019-11-09 11:49:13,782 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-11-49-13/reference/.\n",
      "2019-11-09 11:49:14,050 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmp_nrp7e5z/model.\n",
      "[2019-11-09 11:49:14,050 INFO] Saved processed files to ../temp/tmp_nrp7e5z/model.\n",
      "2019-11-09 11:49:14,062 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmpa5rwxi4a/rouge_conf.xml\n",
      "[2019-11-09 11:49:14,062 INFO] Written ROUGE configuration to ../temp/tmpa5rwxi4a/rouge_conf.xml\n",
      "2019-11-09 11:49:14,062 [MainThread  ] [INFO ]  Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpa5rwxi4a/rouge_conf.xml\n",
      "[2019-11-09 11:49:14,062 INFO] Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmpa5rwxi4a/rouge_conf.xml\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.53045 (95%-conf.int. 0.52265 - 0.53836)\n",
      "1 ROUGE-1 Average_P: 0.37649 (95%-conf.int. 0.37000 - 0.38324)\n",
      "1 ROUGE-1 Average_F: 0.42536 (95%-conf.int. 0.41953 - 0.43146)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.24722 (95%-conf.int. 0.23970 - 0.25508)\n",
      "1 ROUGE-2 Average_P: 0.17560 (95%-conf.int. 0.16975 - 0.18187)\n",
      "1 ROUGE-2 Average_F: 0.19783 (95%-conf.int. 0.19184 - 0.20398)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.48475 (95%-conf.int. 0.47688 - 0.49228)\n",
      "1 ROUGE-L Average_P: 0.34486 (95%-conf.int. 0.33857 - 0.35179)\n",
      "1 ROUGE-L Average_F: 0.38920 (95%-conf.int. 0.38348 - 0.39504)\n",
      "\n",
      "[2019-11-09 11:49:30,036 INFO] Rouges at step 0 \n",
      ">> ROUGE-F(1/2/3/l): 42.54/19.78/38.92\n",
      "ROUGE-R(1/2/3/l): 53.04/24.72/48.48\n",
      "\n",
      "[2019-11-09 11:49:30,036 INFO] Validation xent: 5.38284 at step 0\n"
     ]
    }
   ],
   "source": [
    "%cd PreSumm/src\n",
    "!python train.py -task ext -mode test -test_from ../pretrained/bertext_cnndm_transformer.pt -batch_size 32 -test_batch_size 500 -bert_data_path ../small_data/cnndm -log_file ../logs/pretrained_ext_bert_cnndm -report_rouge True  -sep_optim true -use_interval true -visible_gpus -1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../results/pretrained_ext_bert_cnndm_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN_DM extractive from Pretrained BERT but finetuned for BertSUM\n",
    "Here you have to train the model and then evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PreSumm/src'\n",
      "/Users/adas1/Aditi/personal/school/266/project/PreSumm/src\n",
      "[2019-11-09 12:14:13,870 INFO] Device ID -1\n",
      "[2019-11-09 12:14:13,870 INFO] Device cpu\n",
      "[2019-11-09 12:14:14,321 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 12:14:14,323 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 12:14:14,724 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "Aditi 1\n",
      "[2019-11-09 12:14:16,411 INFO] ExtSummarizer(\n",
      "  (bert): Bert(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ext_layer): ExtTransformerEncoder(\n",
      "    (pos_emb): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer_inter): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (wo): Linear(in_features=768, out_features=1, bias=True)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "gpu_rank 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-09 12:14:16,421 INFO] * number of parameters: 120512513\n",
      "[2019-11-09 12:14:16,421 INFO] Start training...\n",
      "[2019-11-09 12:14:16,530 INFO] Loading train dataset from ../small_data/cnndm.train.143.bert.pt, number of examples: 1084\n",
      "[2019-11-09 12:17:27,118 INFO] Step 50/ 1000; xent: 4.41; lr: 0.0002828;   1 docs/s;    191 sec\n",
      "[2019-11-09 12:20:56,063 INFO] Step 100/ 1000; xent: 3.23; lr: 0.0002000;   1 docs/s;    400 sec\n",
      "[2019-11-09 12:24:15,563 INFO] Step 150/ 1000; xent: 3.13; lr: 0.0001633;   1 docs/s;    599 sec\n",
      "[2019-11-09 12:27:35,911 INFO] Step 200/ 1000; xent: 3.15; lr: 0.0001414;   1 docs/s;    799 sec\n",
      "[2019-11-09 12:31:20,790 INFO] Step 250/ 1000; xent: 3.12; lr: 0.0001265;   1 docs/s;   1024 sec\n",
      "[2019-11-09 12:34:55,520 INFO] Step 300/ 1000; xent: 3.11; lr: 0.0001155;   1 docs/s;   1239 sec\n",
      "[2019-11-09 12:38:34,061 INFO] Step 350/ 1000; xent: 3.34; lr: 0.0001069;   1 docs/s;   1458 sec\n",
      "[2019-11-09 12:42:16,126 INFO] Step 400/ 1000; xent: 3.26; lr: 0.0001000;   1 docs/s;   1680 sec\n",
      "[2019-11-09 12:45:54,622 INFO] Step 450/ 1000; xent: 3.34; lr: 0.0000943;   1 docs/s;   1898 sec\n",
      "[2019-11-09 12:49:36,818 INFO] Step 500/ 1000; xent: 3.21; lr: 0.0000894;   1 docs/s;   2120 sec\n",
      "[2019-11-09 12:49:36,820 INFO] Saving checkpoint ../models/bert_classifier/model_step_500.pt\n",
      "[2019-11-09 12:52:24,853 INFO] Loading train dataset from ../small_data/cnndm.train.143.bert.pt, number of examples: 1084\n",
      "[2019-11-09 12:52:55,603 INFO] Step 550/ 1000; xent: 3.16; lr: 0.0000853;   1 docs/s;   2319 sec\n",
      "[2019-11-09 12:56:13,007 INFO] Step 600/ 1000; xent: 3.08; lr: 0.0000816;   1 docs/s;   2516 sec\n",
      "[2019-11-09 12:59:28,860 INFO] Step 650/ 1000; xent: 3.25; lr: 0.0000784;   1 docs/s;   2712 sec\n",
      "[2019-11-09 13:02:41,584 INFO] Step 700/ 1000; xent: 3.01; lr: 0.0000756;   1 docs/s;   2905 sec\n",
      "[2019-11-09 13:05:55,249 INFO] Step 750/ 1000; xent: 3.19; lr: 0.0000730;   1 docs/s;   3099 sec\n",
      "[2019-11-09 13:44:46,639 INFO] Step 800/ 1000; xent: 3.13; lr: 0.0000707;   0 docs/s;   5430 sec\n",
      "[2019-11-09 13:48:02,174 INFO] Step 850/ 1000; xent: 3.03; lr: 0.0000686;   1 docs/s;   5626 sec\n",
      "[2019-11-09 13:51:25,938 INFO] Step 900/ 1000; xent: 3.41; lr: 0.0000667;   1 docs/s;   5829 sec\n",
      "[2019-11-09 13:55:27,333 INFO] Step 950/ 1000; xent: 3.22; lr: 0.0000649;   1 docs/s;   6071 sec\n",
      "[2019-11-09 13:59:00,578 INFO] Step 1000/ 1000; xent: 3.15; lr: 0.0000632;   1 docs/s;   6284 sec\n",
      "[2019-11-09 13:59:00,580 INFO] Saving checkpoint ../models/bert_classifier/model_step_1000.pt\n",
      "[2019-11-09 13:59:01,565 INFO] Loading train dataset from ../small_data/cnndm.train.143.bert.pt, number of examples: 1084\n",
      "Total stats :  <models.reporter_ext.Statistics object at 0x7f83d36b5c50>\n"
     ]
    }
   ],
   "source": [
    "%cd PreSumm/src\n",
    "!python train.py -task ext -mode train -bert_data_path ../small_data/cnndm -ext_dropout 0.1 -model_path ../models/bert_classifier -lr 2e-3 -visible_gpus -1 -report_every 50 -save_checkpoint_steps 500 -batch_size 30 -train_steps 1000 -accum_count 2 -log_file ../logs/ext_bert_cnndm -use_interval true -warmup_steps 10 -max_pos 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate with Rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PreSumm/src'\n",
      "/Users/adas1/Aditi/personal/school/266/project/PreSumm/src\n",
      "[2019-11-09 14:36:05,500 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
      "Namespace(accum_count=1, alpha=0.95, batch_size=30, beam_size=5, bert_data_path='../small_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/ext_val_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='validate', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/ext_val_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=50, test_from='', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2019-11-09 14:36:06,496 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 14:36:06,498 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 14:36:06,894 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 14:36:08,697 INFO] Loading valid dataset from ../small_data/cnndm.valid.6.bert.pt, number of examples: 1362\n",
      "gpu_rank 0\n",
      "[2019-11-09 14:36:08,700 INFO] * number of parameters: 120512513\n",
      "[2019-11-09 14:50:16,727 INFO] Validation xent: 6.19958 at step 1000\n",
      "[2019-11-09 14:50:16,952 INFO] Loading checkpoint from ../models/bert_classifier/model_step_1000.pt\n",
      "Namespace(accum_count=1, alpha=0.95, batch_size=30, beam_size=5, bert_data_path='../small_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/ext_val_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='validate', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/ext_val_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='ext', temp_dir='../temp', test_all=False, test_batch_size=50, test_from='', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2019-11-09 14:50:18,068 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 14:50:18,068 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 14:50:18,449 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 14:50:20,612 INFO] Loading test dataset from ../small_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
      "gpu_rank 0\n",
      "[2019-11-09 14:50:20,614 INFO] * number of parameters: 120512513\n",
      "1485\n",
      "1485\n",
      "2019-11-09 15:08:42,027 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2019-11-09 15:08:42,027 INFO] Writing summaries.\n",
      "2019-11-09 15:08:42,029 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpx_o9d1_w/system and model files to ../temp/tmpx_o9d1_w/model.\n",
      "[2019-11-09 15:08:42,029 INFO] Processing summaries. Saving system files to ../temp/tmpx_o9d1_w/system and model files to ../temp/tmpx_o9d1_w/model.\n",
      "2019-11-09 15:08:42,029 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-15-08-41/candidate/.\n",
      "[2019-11-09 15:08:42,029 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-15-08-41/candidate/.\n",
      "2019-11-09 15:08:42,625 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpx_o9d1_w/system.\n",
      "[2019-11-09 15:08:42,625 INFO] Saved processed files to ../temp/tmpx_o9d1_w/system.\n",
      "2019-11-09 15:08:42,625 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-15-08-41/reference/.\n",
      "[2019-11-09 15:08:42,625 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-15-08-41/reference/.\n",
      "2019-11-09 15:08:43,038 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpx_o9d1_w/model.\n",
      "[2019-11-09 15:08:43,038 INFO] Saved processed files to ../temp/tmpx_o9d1_w/model.\n",
      "2019-11-09 15:08:43,054 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmp3zikg2z0/rouge_conf.xml\n",
      "[2019-11-09 15:08:43,054 INFO] Written ROUGE configuration to ../temp/tmp3zikg2z0/rouge_conf.xml\n",
      "2019-11-09 15:08:43,054 [MainThread  ] [INFO ]  Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp3zikg2z0/rouge_conf.xml\n",
      "[2019-11-09 15:08:43,054 INFO] Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmp3zikg2z0/rouge_conf.xml\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.50667 (95%-conf.int. 0.49862 - 0.51535)\n",
      "1 ROUGE-1 Average_P: 0.34231 (95%-conf.int. 0.33559 - 0.34884)\n",
      "1 ROUGE-1 Average_F: 0.39384 (95%-conf.int. 0.38760 - 0.39991)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.22061 (95%-conf.int. 0.21322 - 0.22905)\n",
      "1 ROUGE-2 Average_P: 0.14846 (95%-conf.int. 0.14267 - 0.15378)\n",
      "1 ROUGE-2 Average_F: 0.17082 (95%-conf.int. 0.16471 - 0.17691)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.46006 (95%-conf.int. 0.45246 - 0.46850)\n",
      "1 ROUGE-L Average_P: 0.31131 (95%-conf.int. 0.30461 - 0.31782)\n",
      "1 ROUGE-L Average_F: 0.35794 (95%-conf.int. 0.35179 - 0.36398)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-09 15:09:02,262 INFO] Rouges at step 1000 \n",
      ">> ROUGE-F(1/2/3/l): 39.38/17.08/35.79\n",
      "ROUGE-R(1/2/3/l): 50.67/22.06/46.01\n",
      "\n",
      "[2019-11-09 15:09:02,262 INFO] Validation xent: 6.18543 at step 1000\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 148, in <module>\n",
      "    validate_ext(args, device_id)\n",
      "  File \"/Users/adas1/Aditi/personal/school/266/project/PreSumm/src/train_extractive.py\", line 140, in validate_ext\n",
      "    cp_files = sorted(glob.glob(os.path.join(args.model_path, 'model_step_*.pt')))\n",
      "  File \"/Users/adas1/anaconda3/lib/python3.7/glob.py\", line 20, in glob\n",
      "    return list(iglob(pathname, recursive=recursive))\n",
      "  File \"/Users/adas1/anaconda3/lib/python3.7/glob.py\", line 72, in _iglob\n",
      "    for name in glob_in_dir(dirname, basename, dironly):\n",
      "  File \"/Users/adas1/anaconda3/lib/python3.7/glob.py\", line 80, in _glob1\n",
      "    names = list(_iterdir(dirname, dironly))\n",
      "  File \"/Users/adas1/anaconda3/lib/python3.7/glob.py\", line 122, in _iterdir\n",
      "    for entry in it:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%cd PreSumm/src\n",
    "!python train.py -task ext -mode validate -batch_size 30 -test_batch_size 50 -bert_data_path ../small_data/cnndm -log_file ../logs/ext_val_bert_cnndm -model_path ../models/bert_classifier -sep_optim true -use_interval true -visible_gpus -1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/ext_val_bert_cnndm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN_DM abstractive from Pretrained BERT but finetuned for BertSUM\n",
    "Here you have to train extractive model first and pass that model to the abstractive model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PreSumm/src'\n",
      "/Users/adas1/Aditi/personal/school/266/project/PreSumm/src\n",
      "[2019-11-09 19:45:19,399 INFO] Namespace(accum_count=5, alpha=0.6, batch_size=140, beam_size=5, bert_data_path='../small_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='../models/bert_classifier/model_step_1000.pt', log_file='../logs/abs_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.2, max_grad_norm=0, max_length=150, max_pos=512, max_tgt_len=140, min_length=15, mode='train', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=100, report_rouge=True, result_path='../results/cnndm', save_checkpoint_steps=100, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=200, test_from='', test_start_from=-1, train_from='', train_steps=100, use_bert_emb=True, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=200, warmup_steps_dec=10000, world_size=1)\n",
      "[2019-11-09 19:45:19,400 INFO] Device ID -1\n",
      "[2019-11-09 19:45:19,400 INFO] Device cpu\n",
      "[2019-11-09 19:45:19,402 INFO] Loading bert from extractive model ../models/bert_classifier/model_step_1000.pt\n",
      "[2019-11-09 19:45:20,739 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 19:45:20,740 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 19:45:21,136 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 19:45:25,167 INFO] AbsSummarizer(\n",
      "  (bert): Bert(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "    (pos_emb): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_values): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (linear_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (final_linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=768, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (layer_norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.2, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=30522, bias=True)\n",
      "    (1): LogSoftmax()\n",
      "  )\n",
      ")\n",
      "[2019-11-09 19:45:25,574 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "gpu_rank 0\n",
      "[2019-11-09 19:45:25,669 INFO] * number of parameters: 180222522\n",
      "[2019-11-09 19:45:25,669 INFO] Start training...\n",
      "[2019-11-09 19:45:25,768 INFO] Loading train dataset from ../small_data/cnndm.train.143.bert.pt, number of examples: 1084\n",
      "[2019-11-09 20:19:17,229 INFO] Step 100/  100; acc:   0.79; ppl: 1628.46; xent: 7.40; lr: 0.00007071;   0/ 29 tok/s;   2031 sec\n",
      "[2019-11-09 20:19:17,232 INFO] Saving checkpoint ../models/bert_classifier/model_step_100.pt\n",
      "[2019-11-09 20:19:18,614 INFO] Loading train dataset from ../small_data/cnndm.train.143.bert.pt, number of examples: 1084\n"
     ]
    }
   ],
   "source": [
    "%cd PreSumm/src\n",
    "!python train.py  -task abs -mode train -bert_data_path ../small_data/cnndm -dec_dropout 0.2  -model_path ../models/bert_classifier  -sep_optim true -lr_bert 0.002 -lr_dec 0.2 -save_checkpoint_steps 100 -batch_size 140 -train_steps 100 -report_every 100 -accum_count 5 -use_bert_emb true -use_interval true -warmup_steps_bert 200 -warmup_steps_dec 10000 -max_pos 512 -visible_gpus -1 -log_file ../logs/abs_bert_cnndm  -load_from_extractive ../models/bert_classifier/model_step_1000.pt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'PreSumm/src'\n",
      "/Users/adas1/Aditi/personal/school/266/project/PreSumm/src\n",
      "[2019-11-09 20:26:53,744 INFO] Loading checkpoint from ../models/bert_classifier/model_step_100.pt\n",
      "Namespace(accum_count=1, alpha=0.95, batch_size=30, beam_size=5, bert_data_path='../small_data/cnndm', beta1=0.9, beta2=0.999, block_trigram=True, dec_dropout=0.2, dec_ff_size=2048, dec_heads=8, dec_hidden_size=768, dec_layers=6, enc_dropout=0.2, enc_ff_size=512, enc_hidden_size=512, enc_layers=6, encoder='bert', ext_dropout=0.2, ext_ff_size=2048, ext_heads=8, ext_hidden_size=768, ext_layers=2, finetune_bert=True, generator_shard_size=32, gpu_ranks=[0], label_smoothing=0.1, large=False, load_from_extractive='', log_file='../logs/val_abs_bert_cnndm', lr=1, lr_bert=0.002, lr_dec=0.002, max_grad_norm=0, max_length=200, max_pos=512, max_tgt_len=140, min_length=50, mode='test', model_path='../models/bert_classifier', optim='adam', param_init=0, param_init_glorot=True, recall_eval=False, report_every=1, report_rouge=True, result_path='../logs/abs_tes_bert_cnndm', save_checkpoint_steps=5, seed=666, sep_optim=True, share_emb=False, task='abs', temp_dir='../temp', test_all=False, test_batch_size=500, test_from='../models/bert_classifier/model_step_100.pt', test_start_from=-1, train_from='', train_steps=1000, use_bert_emb=False, use_interval=True, visible_gpus='-1', warmup_steps=8000, warmup_steps_bert=8000, warmup_steps_dec=8000, world_size=1)\n",
      "[2019-11-09 20:26:55,423 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c\n",
      "[2019-11-09 20:26:55,424 INFO] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[2019-11-09 20:26:55,813 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "[2019-11-09 20:27:00,083 INFO] Loading test dataset from ../small_data/cnndm.test.5.bert.pt, number of examples: 1485\n",
      "[2019-11-09 20:27:00,491 INFO] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../temp/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "[2019-11-09 22:00:39,166 INFO] Calculating Rouge\n",
      "1485\n",
      "1485\n",
      "2019-11-09 22:00:39,758 [MainThread  ] [INFO ]  Writing summaries.\n",
      "[2019-11-09 22:00:39,758 INFO] Writing summaries.\n",
      "2019-11-09 22:00:39,759 [MainThread  ] [INFO ]  Processing summaries. Saving system files to ../temp/tmpunwldmrc/system and model files to ../temp/tmpunwldmrc/model.\n",
      "[2019-11-09 22:00:39,759 INFO] Processing summaries. Saving system files to ../temp/tmpunwldmrc/system and model files to ../temp/tmpunwldmrc/model.\n",
      "2019-11-09 22:00:39,759 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-22-00-39/candidate/.\n",
      "[2019-11-09 22:00:39,759 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-22-00-39/candidate/.\n",
      "2019-11-09 22:00:40,070 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpunwldmrc/system.\n",
      "[2019-11-09 22:00:40,070 INFO] Saved processed files to ../temp/tmpunwldmrc/system.\n",
      "2019-11-09 22:00:40,070 [MainThread  ] [INFO ]  Processing files in ../temp/rouge-tmp-2019-11-09-22-00-39/reference/.\n",
      "[2019-11-09 22:00:40,070 INFO] Processing files in ../temp/rouge-tmp-2019-11-09-22-00-39/reference/.\n",
      "2019-11-09 22:00:40,363 [MainThread  ] [INFO ]  Saved processed files to ../temp/tmpunwldmrc/model.\n",
      "[2019-11-09 22:00:40,363 INFO] Saved processed files to ../temp/tmpunwldmrc/model.\n",
      "2019-11-09 22:00:40,374 [MainThread  ] [INFO ]  Written ROUGE configuration to ../temp/tmphjovgfnw/rouge_conf.xml\n",
      "[2019-11-09 22:00:40,374 INFO] Written ROUGE configuration to ../temp/tmphjovgfnw/rouge_conf.xml\n",
      "2019-11-09 22:00:40,374 [MainThread  ] [INFO ]  Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmphjovgfnw/rouge_conf.xml\n",
      "[2019-11-09 22:00:40,374 INFO] Running ROUGE with command /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /Users/adas1/Aditi/personal/school/266/project/pyrouge/tools/ROUGE-1.5.5/data -c 95 -m -r 1000 -n 2 -a ../temp/tmphjovgfnw/rouge_conf.xml\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "1 ROUGE-1 Average_P: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "1 ROUGE-1 Average_F: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "1 ROUGE-2 Average_P: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "1 ROUGE-2 Average_F: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "1 ROUGE-L Average_P: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "1 ROUGE-L Average_F: 0.00000 (95%-conf.int. 0.00000 - 0.00000)\n",
      "\n",
      "[2019-11-09 22:00:48,767 INFO] Rouges at step 100 \n",
      ">> ROUGE-F(1/2/3/l): 0.00/0.00/0.00\n",
      "ROUGE-R(1/2/3/l): 0.00/0.00/0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd PreSumm/src\n",
    "!python train.py -task abs -mode test -test_from ../models/bert_classifier/model_step_100.pt  -batch_size 30 -test_batch_size 500 -bert_data_path ../small_data/cnndm -log_file ../logs/val_abs_bert_cnndm -model_path ../models/bert_classifier -sep_optim true -use_interval true -visible_gpus -1 -max_pos 512 -max_length 200 -alpha 0.95 -min_length 50 -result_path ../logs/abs_tes_bert_cnndm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Transformer Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adas1/Aditi/personal/school/266/project/transformers/examples\n",
      "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt not found in cache or force_download set to True, downloading to /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpgvn1p05d\n",
      "100%|████████████████████████████████| 213450/213450 [00:00<00:00, 831803.43B/s]\n",
      "INFO:transformers.file_utils:copying /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpgvn1p05d to cache at /Users/adas1/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:transformers.file_utils:creating metadata file for /Users/adas1/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:transformers.file_utils:removing temp file /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpgvn1p05d\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /Users/adas1/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json not found in cache or force_download set to True, downloading to /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmp19db0kto\n",
      "100%|██████████████████████████████████████| 313/313 [00:00<00:00, 138002.43B/s]\n",
      "INFO:transformers.file_utils:copying /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmp19db0kto to cache at /Users/adas1/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "INFO:transformers.file_utils:creating metadata file for /Users/adas1/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "INFO:transformers.file_utils:removing temp file /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmp19db0kto\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /Users/adas1/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /Users/adas1/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "INFO:transformers.configuration_utils:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpfnx9d0nw\n",
      "100%|████████████████████████| 435779157/435779157 [00:30<00:00, 14097602.77B/s]\n",
      "INFO:transformers.file_utils:copying /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpfnx9d0nw to cache at /Users/adas1/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "INFO:transformers.file_utils:creating metadata file for /Users/adas1/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "INFO:transformers.file_utils:removing temp file /var/folders/7m/bpr251m543ndyscyxrt1_m0r0000gn/T/tmpfnx9d0nw\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /Users/adas1/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "WARNING:__main__:Process rank: 0, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
      "INFO:__main__:Training/evaluation parameters Namespace(data_dir='', device=device(type='cpu'), do_evaluate=False, do_overwrite_output_dir=False, do_train=True, gradient_accumulation_steps=1, max_grad_norm=1.0, max_steps=-1, model_name_or_path='bert-base-cased', model_type='bert', n_gpu=0, num_train_epochs=10, output_dir='../output', per_gpu_train_batch_size=4, seed=42, to_cpu=False)\n",
      "Traceback (most recent call last):\n",
      "  File \"run_summarization_finetuning.py\", line 488, in <module>\n",
      "    main()\n",
      "  File \"run_summarization_finetuning.py\", line 453, in main\n",
      "    global_step, tr_loss = train(args, model, tokenizer)\n",
      "  File \"run_summarization_finetuning.py\", line 168, in train\n",
      "    train_dataset = load_and_cache_examples(args, tokenizer)\n",
      "  File \"run_summarization_finetuning.py\", line 64, in load_and_cache_examples\n",
      "    dataset = CNNDailyMailDataset(tokenizer, data_dir=args.data_dir)\n",
      "  File \"/Users/adas1/Aditi/personal/school/266/project/transformers/examples/utils_summarization.py\", line 29, in __init__\n",
      "    assert os.path.isdir(data_dir)\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/adas1/Aditi/personal/school/266/project/transformers/examples\n",
    "!export DATA_PATH=/Users/adas1/Aditi/personal/school/266/project/PreSumm/small_data\n",
    "\n",
    "!python run_summarization_finetuning.py --output_dir=../output \\\n",
    "    --model_type=bert \\\n",
    "    --model_name_or_path=bert-base-cased \\\n",
    "    --do_train True \\\n",
    "    --data_dir=$DATA_PATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
